{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UrlExtractorImagesAttributes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmillanm/ColabScripts/blob/master/UrlExtractorImagesAttributes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc3rS4uPhTvt"
      },
      "source": [
        "%%bash\n",
        "pip install cairosvg > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r-p-ohxe_ls"
      },
      "source": [
        "from bs4 import BeautifulSoup, element\n",
        "import cairosvg\n",
        "import csv\n",
        "from io import BytesIO \n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import re\n",
        "import requests\n",
        "import time\n",
        "from typing import Dict, List, Optional, Text, Tuple\n",
        "import urllib.request, urllib.parse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOlDQ7jp7HcN"
      },
      "source": [
        "def _get_urls_from_csv(path: Text) -> List:\n",
        "  contents = []\n",
        "  \n",
        "  with open(path,'r') as csvf: # Open file in read mode\n",
        "      urls = csv.reader(csvf)\n",
        "      for url in urls:\n",
        "          contents.append(url)\n",
        "  \n",
        "  return contents"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YsUUKpxpr_4"
      },
      "source": [
        "def _base_url(url:Text, \n",
        "              with_path:bool=False) -> Text:\n",
        "    parsed = urllib.parse.urlparse(url)\n",
        "    path   = '/'.join(parsed.path.split('/')[:-1]) if with_path else ''\n",
        "    parsed = parsed._replace(path=path)\n",
        "    parsed = parsed._replace(params='')\n",
        "    parsed = parsed._replace(query='')\n",
        "    parsed = parsed._replace(fragment='')\n",
        "\n",
        "    return parsed.geturl()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybk6CElVfAi0"
      },
      "source": [
        "def _request_html_from_url(url:Text, \n",
        "                           headers:Dict) -> bool:\n",
        "\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "      response.__len__ = len([response])\n",
        "      return response\n",
        "    \n",
        "    return \"request_html_from_url status_code %s\" % response.status_code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icsHzq9Ol_P7"
      },
      "source": [
        "def _find_img_tags(response: requests.models.Response,\n",
        "                   parser: 'html.parser' or 'lxml' or 'lxml-xml' or 'html5lib') -> element.ResultSet:\n",
        "  \n",
        "  soup = BeautifulSoup(response.text, parser)\n",
        "  script_tags = soup.findAll('img')\n",
        "\n",
        "  return script_tags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asYz2fK8vshO"
      },
      "source": [
        "columns = ['path', \n",
        "            'class', \n",
        "            'alt',\n",
        "            'title', \n",
        "            'html_tag', \n",
        "            'file_extension']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kDgDp9RxC-v"
      },
      "source": [
        "def _value_extractor_from_attr(html_tag: element.Tag, \n",
        "                              attrs: List) -> List:\n",
        "\n",
        "  attributes = {'path':str(html_tag.get('src')), \n",
        "                'class':str(html_tag.get('class')), \n",
        "                'alt':str(html_tag.get('alt')), \n",
        "                'title': str(html_tag.get('title')),\n",
        "                'html_tag':str(html_tag), \n",
        "                'file_extension':str(html_tag.get('src')).split(\".\")[-1]}\n",
        "  \n",
        "  desired_attributes = {k: v for k, v in attributes.items() if k in attrs}\n",
        "\n",
        "  return list(desired_attributes.values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjMSHnfff3Ta"
      },
      "source": [
        "def _extract_data_images(script_tags: element.ResultSet, \n",
        "                         columns: List) -> pd.core.frame.DataFrame:\n",
        "    data=[]\n",
        "    df = pd.DataFrame(columns=columns)\n",
        "\n",
        "    for script in script_tags:\n",
        "      values = _value_extractor_from_attr(script, columns)      \n",
        "      data.append(dict(zip(columns, values)))\n",
        "\n",
        "    df = df.append(data, True)\n",
        "    \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIXEN4vdaTq2"
      },
      "source": [
        "def _image_size(url_img: Text) -> Tuple[int, int]:\n",
        "  # Tested on jpg, jpeg and png\n",
        "  # For svg, use svg size\n",
        "  response = requests.get(url_img)\n",
        "  img = Image.open(BytesIO(response.content))\n",
        "  img_size = img.size\n",
        "  img.close()\n",
        "\n",
        "  return img_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIgXkI5ahxtk"
      },
      "source": [
        " def _get_content_length(url_img: Text, \n",
        "                         headers) -> str:  \n",
        "  req = urllib.request.Request(url_img, method='HEAD', headers=headers)\n",
        "  f = urllib.request.urlopen(req)\n",
        "  length = f.headers['Content-Length']\n",
        "\n",
        "  return length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOFVf9mliVfB"
      },
      "source": [
        "def _svg_size(url_img: Text) -> Tuple[int, int]:\n",
        "  response = requests.get(url_img)\n",
        "  out = BytesIO() \n",
        "  cairosvg.svg2png(url=url_img, write_to=out)\n",
        "  img = Image.open(out)\n",
        "  img_size = img.size\n",
        "  img.close()\n",
        "\n",
        "  return img_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQR0YMgRs4qp"
      },
      "source": [
        "def _get_img_size(url_img: Text, \n",
        "                  img_type: Text) -> float:\n",
        "  if img_type == 'svg':\n",
        "    try:\n",
        "      img_size = _svg_size(url_img)\n",
        "    except:\n",
        "      #outlier to detect errors\n",
        "      img_size = 999999999999999\n",
        "  else:\n",
        "    try:\n",
        "      img_size = _image_size(url_img)\n",
        "    except:\n",
        "      #outlier to detect errors\n",
        "      img_size = 999999999999999\n",
        "  return img_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDR1pvHBZuSF"
      },
      "source": [
        "def image_scanner_from_url(url: Text, \n",
        "                           headers: Dict) -> pd.core.frame.DataFrame:\n",
        "  html = _request_html_from_url(url, headers)\n",
        "\n",
        "  if type(html) == str:\n",
        "    raise Exception(html)\n",
        "\n",
        "  img_tags = _find_img_tags(html, 'html.parser')\n",
        "  data_images = _extract_data_images(img_tags, columns)\n",
        "  \n",
        "  return data_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0TNcaj2mcBi"
      },
      "source": [
        "def image_scanner_add_url(url: Text, \n",
        "                          data_images: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
        "\n",
        "  data_images['url_img'] = data_images.apply(\n",
        "      lambda x: x.path \\\n",
        "      if x.path.startswith('http')\\\n",
        "      else f\"{_base_url(url)}/{x.path}\", \n",
        "      axis=1)\n",
        "\n",
        "  return data_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPBWPvJQsFwR"
      },
      "source": [
        "def image_scanner_add_size(data_images: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
        "\n",
        "  data_images['size'] = data_images.apply(\n",
        "      lambda x: _get_img_size(x.url_img, x.file_extension), \n",
        "      axis=1)\n",
        "\n",
        "  return data_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q19R3LUst8ay"
      },
      "source": [
        "def image_scanner_add_content_length(data_images: pd.core.frame.DataFrame, \n",
        "                                     headers: Dict) -> pd.core.frame.DataFrame:\n",
        "\n",
        "  data_images['content_length'] = data_images.apply(\n",
        "      lambda x: float(_get_content_length(x.url_img, headers)), \n",
        "      axis=1)\n",
        "\n",
        "  return data_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqiXDWKR2e-q"
      },
      "source": [
        "def parse_all_info_img(url: Text, \n",
        "                       headers: Dict) -> pd.core.frame.DataFrame:\n",
        "  \n",
        "  data_images = image_scanner_from_url(url, headers)\n",
        "  \n",
        "  data_images = image_scanner_add_url(url, data_images)\n",
        "  data_images = image_scanner_add_size(data_images)\n",
        "  data_images = image_scanner_add_content_length(data_images, headers)\n",
        "  data_images['content_length_kB'] = data_images.content_length/1000\n",
        "  data_images['url'] = url\n",
        "\n",
        "  return data_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k09afiHL39Qw"
      },
      "source": [
        "def pipe_all_info_img(all_info: pd.core.frame.DataFrame, \n",
        "                      columns_to_select: List):\n",
        "  return all_info[columns_to_select]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUVP3QXJ4V08"
      },
      "source": [
        "def make_extraction_process(url: Text, \n",
        "                            headers: Dict, columns_to_select: List) -> pd.core.frame.DataFrame:\n",
        "\n",
        "    all_info = parse_all_info_img(url, headers)\n",
        "\n",
        "    data = pipe_all_info_img(all_info, columns_to_select)\n",
        "\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGOtLy1BodmN"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  # you only have to change the csv_path and assign a name for the new file\n",
        "  # csv with the list of urls without column title\n",
        "  csv_path = 'path/to/your.csv'\n",
        "  data_extration_name = 'results.csv'\n",
        "  \n",
        "  if 'data' in globals():\n",
        "    del(data)\n",
        "  urls = _get_urls_from_csv(csv_path)\n",
        "  headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
        "  columns_to_select = ['url','path', 'alt', 'title', 'size', 'content_length_kB']\n",
        "\n",
        "  run = 1\n",
        "  for url in urls:\n",
        "    if run == 1:\n",
        "      data = make_extraction_process(url[0], headers, columns_to_select)\n",
        "    else:\n",
        "      data = data.append(make_extraction_process(url[0], headers, columns_to_select), ignore_index=True)\n",
        "    run+=1\n",
        "\n",
        "  data.to_csv(data_extration_name)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}